{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "%matplotlib inline\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import mr_word_count\n",
    "importlib.reload(mr_word_count)\n",
    "from mr_word_count import MRWordFrequencyCount\n",
    "from mrjob.job import MRJob\n",
    "import mapreduce as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inwood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>description</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10034</td>\n",
       "      <td>At the northernmost end of Manhattan Island, i...</td>\n",
       "      <td>Inwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10034</td>\n",
       "      <td>From the beginning. Guadalupe Bar and Grill ha...</td>\n",
       "      <td>Inwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10034</td>\n",
       "      <td>\"We offer a new concept, dedicated to rescue o...</td>\n",
       "      <td>Inwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10040</td>\n",
       "      <td>The Cloisters museum and gardens, the branch o...</td>\n",
       "      <td>Inwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10034</td>\n",
       "      <td>The Dyckman Farmhouse Museum is a visual treat...</td>\n",
       "      <td>Inwood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZIPCODE                                        description Neighborhood\n",
       "0    10034  At the northernmost end of Manhattan Island, i...       Inwood\n",
       "1    10034  From the beginning. Guadalupe Bar and Grill ha...       Inwood\n",
       "2    10034  \"We offer a new concept, dedicated to rescue o...       Inwood\n",
       "3    10040  The Cloisters museum and gardens, the branch o...       Inwood\n",
       "4    10034  The Dyckman Farmhouse Museum is a visual treat...       Inwood"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str[:161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this link is really helpful in understanding what each of the nlt codes does (tokenizer, remove words, lemmatizer, etc.)\n",
    "# all the lambda apply's and functions you see below are because of this blog post\n",
    "\n",
    "# https://towardsdatascience.com/nlp-for-beginners-cleaning-preprocessing-text-data-ae8e306bef0f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer turns each string in the description column to a list of words\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(lambda x: tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [at, the, northernmost, end, of, manhattan, is...\n",
       "1    [from, the, beginning., guadalupe, bar, and, g...\n",
       "2    [\"we, offer, a, new, concept,, dedicated, to, ...\n",
       "3    [the, cloisters, museum, and, gardens,, the, b...\n",
       "4    [the, dyckman, farmhouse, museum, is, a, visua...\n",
       "5    [this, marvelous, experience, came, as, a, res...\n",
       "6    [we, have, expanded, to, a, 1,500, square, foo...\n",
       "7    [this, business, was, founded, on, the, premis...\n",
       "8    [havana, tacos, was, inspired, by, a, diverse,...\n",
       "9    [in, what, was, once, a, desolate, industrial,...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer not totally sure what it does but it helps with the getting the gist of the word\n",
    "# gotta read the towards data science post\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [northernmost, end, manhattan, island,, shadow...\n",
       "1     [beginning., guadalupe, bar, grill, built, rep...\n",
       "2     [\"we, offer, new, concept,, dedicated, rescue,...\n",
       "3     [cloister, museum, gardens,, branch, metropoli...\n",
       "4     [dyckman, farmhouse, museum, visual, treat, ev...\n",
       "5     [marvelous, experience, came, result, influenc...\n",
       "6     [expanded, 1,500, square, foot, store, include...\n",
       "7     [business, founded, premise, family., el, nuev...\n",
       "8     [havana, taco, inspired, diverse, cultural, bl...\n",
       "9     [desolate, industrial, district,, come, next, ...\n",
       "10    [experience, essence, latin, fusion, cuisine,,...\n",
       "11    [lower, level, trie, cloister, cloister, museu...\n",
       "12    [wahi’s, industrial, open, space, brings, comm...\n",
       "13    [located, manhattan’s, historic, inwood, neigh...\n",
       "14    [specialize, running, pool, hall, caters, ages...\n",
       "15    [come, enjoy, good, family, atmosphere,, find,...\n",
       "16    [bocaditos, bistro, opened, door, september, 2...\n",
       "17    [established, 1996,, genesis, first, ecuadoria...\n",
       "18    [jimbo’s, hamburger, place, proudly, moving, f...\n",
       "19    [tannat, wine, &, cheese, blend, two, well-kno...\n",
       "20    [located, stone's, throw, good, shepherd, chur...\n",
       "21    [washington, height, newest, sport, bar, &, ca...\n",
       "22    [sushi, mambo,, mission, provide, food-lovers,...\n",
       "23    [chocnyc, upscale, modern, pastry, shop, start...\n",
       "24    [tryon, public, house, craft, beer, &, cocktai...\n",
       "25    [republica, new, dominican, food, party, sensa...\n",
       "26    [restaurant, specializing, modern, mexican, cu...\n",
       "27    [velvet, curtains:, elegant,, modern, discreet...\n",
       "28    [go-greenly, frozen, yogurt, sell, using, eco-...\n",
       "29    [northern, tip, manhattan,, rich, tapestry, cu...\n",
       "30    [il, sole, restaurant, located, heart, inwood....\n",
       "31    [elsa, queen, chicharron,, started, business, ...\n",
       "32    [seawalk, elevates, culinary, experience, prem...\n",
       "33    [twin, donut, opened, first, store, 1959, we'v...\n",
       "34    [make, food, order, using, fresh, ingredients....\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you'll notice here, we don't set the column equal to the updated applied version - I think that results in errors\n",
    "# I tried before, it didn't work, and had to rerun code from the beginning, more than once\n",
    "\n",
    "df['description'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this is where it gets real clunky, and a for loop could've made life easier, but oh well\n",
    "# I created brand new df's for each neighborhood (just duplicates essentially)\n",
    "# each letter for a respective neighborhood\n",
    "\n",
    "df['ZIPCODE'] = df['ZIPCODE'].astype(int)\n",
    "df['description'] = df['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then here, I created a 8 string var's (one for each neighborhood df)\n",
    "# concatenate all the description strings for each neighborhood into one string\n",
    "\n",
    "a = df['description'].str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the words_'letter' are lists of all of all the words\n",
    "# the wordCount_'letter' are dictionaries of the words and their counts\n",
    "# again, there's 8 of these, cause 8 df's / neighborhoods\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "words_a = a.split()\n",
    "wordCount_a = Counter(words_a) #Chelsea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(wordCount_a, orient='index').reset_index()\n",
    "df1 = df1.rename(columns={\"index\": \"word\", 0:'count'})\n",
    "df1['word'] = df1['word'].str.replace(r'[^\\w\\s]+', '')\n",
    "df1 = df1[df1.word != '']\n",
    "df1 = df1.groupby(['word'], as_index=False)['count'].sum()\n",
    "# df1.drop( df1[ df1['count'] == 1 ].index , inplace=True)\n",
    "# df1.drop( df1[ df1['count'] == 2 ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df1[df1['word'] == \"york\"].size>0:\n",
    "    b = df1.loc[df1['word'] == 'new', 'count'].item()\n",
    "    c = df1.loc[df1['word'] == 'york', 'count'].item()\n",
    "\n",
    "    if b == c:\n",
    "        df1.drop(df1[ df1['word'] == 'york' ].index , inplace=True)\n",
    "        df1.drop(df1[ df1['word'] == 'new' ].index , inplace=True)\n",
    "    else:\n",
    "        d = b - c\n",
    "        df1.loc[df1.word == \"new\", \"count\"] = d\n",
    "        df1.drop(df1[ df1['word'] == 'york' ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created new df's that took the top 150 values for each of the 8 neighborhood's / df's\n",
    "# df100 corresponds to df1 which corresponds to Chelsea, so on and so forth...\n",
    "\n",
    "df100 = df1.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 = df100.reset_index(drop=True)\n",
    "df100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
